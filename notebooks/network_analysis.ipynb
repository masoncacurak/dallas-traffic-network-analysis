{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Metrics\n",
    "\n",
    "Build the network graph, compute centrality metrics, detect communities, and save outputs to `data/processed/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4808869",
   "metadata": {},
   "source": [
    "## Prep\n",
    "Run preprocessing and temporal preprocessing if processed files are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to regenerate processed data\n",
    "# !python3 ../src/preprocessing.py\n",
    "# !python3 ../src/temporal_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26cb9f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import helpers / ensure the project `src` directory is on the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dfe6ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/masoncacurak/Downloads/CS_5483/dallas_network_analysis\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# Resolve project root as parent of this notebook's directory\n",
    "NOTEBOOK_DIR = os.path.abspath(os.getcwd())\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir))\n",
    "SRC_DIR = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.append(SRC_DIR)\n",
    "\n",
    "from build_network import load_and_build\n",
    "from centrality_analysis import compute_centrality_measures, save_centrality_rankings\n",
    "from community_detection import detect_communities, save_communities\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad695f",
   "metadata": {},
   "source": [
    "## Build graph\n",
    "Select a time period weight (e.g., `AM`, `Midday`, `PM`, `Evening`) or leave `period=None` to use `weight_type` (`congested`/`freeflow`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d20bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed_nodes.csv...\n",
      "Loading processed_links.csv...\n",
      "Building graph using temporal weight column 'travel_time_Midday'\n",
      "Adding 21389 nodes...\n",
      "Adding 35696 edges...\n",
      "Graph build complete: 21389 nodes, 35696 edges\n",
      "Graph built: 21389 nodes, 35696 edges\n",
      "Loading processed_nodes.csv...\n",
      "Loading processed_links.csv...\n",
      "Building graph using congested_time as weight\n",
      "Adding 21389 nodes...\n",
      "Adding 35696 edges...\n",
      "Graph build complete: 21389 nodes, 35696 edges\n",
      "Graph built: 21389 nodes, 35696 edges\n"
     ]
    }
   ],
   "source": [
    "period = \"Midday\" # options: \"AM\", \"Midday\", \"PM\", \"Evening\", or None\n",
    "G = load_and_build(weight_type=\"congested\", period=period) # if period=None, weight_type=\"congested\" or \"freeflow\"\n",
    "print(f\"Graph built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality metrics\n",
    "Compute degree, betweenness (weighted), and eigenvector centrality --> save rankings to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = compute_centrality_measures(G)\n",
    "centrality_path = save_centrality_rankings(centrality)\n",
    "print(f\"Centrality rankings saved to: {centrality_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community detection\n",
    "Run Louvain on the undirected graph (Set `run_gn_sample=True` to also run Girvanâ€“Newman on sampled subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition, num_comms, sizes = detect_communities(G, run_gn_sample=True)\n",
    "communities_path = save_communities(partition)\n",
    "\n",
    "print(f\"Communities saved to: {communities_path}\")\n",
    "print(f\"Total communities: {num_comms}\")\n",
    "print(f\"Top community sizes: {sizes[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
